{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro til språkmodeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spørsmål\n",
    "- Vi trenger at dte går fortere å kalle på modellen :)\n",
    "- Hvordan gjør vi det med nøkler? Per nå leser denne fortsatt fra .env-filen da jeg ikke ville pushe de til github.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanker\n",
    "\n",
    "- Gi mer info i prompt om situasjonen rundt spørreundersøkelsen og hva det har blitt spurt om. Spesielt i situasjonen hvor vi øsnker å oppsummere den generelle viben av feedbacken i hver kategori. Var folk fornøyde? Ønsker de tiltak for forbedring?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AzureChatOpenAI\n",
    "### Språkmodellene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "# Get environment variables\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "\n",
    "# Variabler heller enn klasser\n",
    "class Llm:\n",
    "    \"\"\"\n",
    "    Class containing the language model.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_GPT_4O_MINI\"],\n",
    "        model=os.environ.get(\"OPENAI_MODEL_GPT_4O-MINI\", default=\"gpt-4o-mini\"),\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "\n",
    "class LlmRes:\n",
    "    \"\"\"\n",
    "    Class containing the language model.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_GPT_3O_MINI\"],\n",
    "        model=os.environ.get(\"OPENAI_MODEL_GPT_3O-MINI\", default=\"o3-mini\"),\n",
    "        reasoning_effort=\"high\",\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Den enkleste måten å bruke AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hei! Hvordan kan jeg hjelpe deg i dag?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 9, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7a53abb7a2', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-84adb657-4f64-4985-8c5d-a0f224d46fc9-0' usage_metadata={'input_tokens': 9, 'output_tokens': 11, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Hei! Hvordan kan jeg hjelpe deg i dag?\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Hei!'\n",
    "response = Llm.llm.invoke(prompt)\n",
    "\n",
    "print(response)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured output\n",
    "### Pydantic-objekter\n",
    "- Gå igjennom hva disse objektene er, hva kan du kreve av outputen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enkel bruk av structured output \n",
    "# Hva i alle dager er pydantic? :D\n",
    "# Lag en enkel klasse og kjør\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "\n",
    "class Categorize(BaseModel):\n",
    "    \"Categorization of feedback on IT-services.\"\n",
    "\n",
    "    # Thoughts: Forklar tankegangen din.\n",
    "    category : str = Field(description=\"The best fitting general category. Only one.\")\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = Llm.llm.with_structured_output(   #Gå igjennom denne, hvordan bruker man structured output?\n",
    "        Categorize, method=\"function_calling\"\n",
    "    )\n",
    "\n",
    "response = structured_llm.invoke(\"Send inn prompt + data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategorizeFromOptions(BaseModel):\n",
    "    \"\"\"Categorization of IT-questionaire feedback.\"\"\"\n",
    "\n",
    "    category: Literal[\n",
    "        \"Network\",\n",
    "        \"IT Training\",\n",
    "        \"IT Support\",\n",
    "        'Other'\n",
    "    ] = Field(\n",
    "        description=\"Categorize the feedback into the most fitting category. If the categories provided are not a perfect fit, default to 'Other'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find potential new categories based on feedback categorized as others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3508461298.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m] = Field(\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class CategorizeFromOptions2(BaseModel):\n",
    "    \"\"\"Categorization of IT-questionaire feedback.\"\"\"\n",
    "\n",
    "    category: Literal[\n",
    "       # Insert the categories you found while exploring the feedback initially categorized as 'Other'.\n",
    "    ] = Field(\n",
    "        description=\"Categorize the feedback into the most fitting category. If the categories provided are not a perfect fit, default to 'Other'.\"\n",
    "    )\n",
    "    reason : str = Field(description=\"Why do you believe this category is the most fitting one? Explain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (2397846824.py, line 51)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Kan de mekke på disse selv? Hvordan kan vi gjøre dette steget mer interaktivt\n",
    "\n",
    "\n",
    "class Categorize_search(BaseModel):\n",
    "    \"\"\"Categorization of IT-questionaire feedback.\"\"\"\n",
    "\n",
    "    categories: Literal[\n",
    "        \"Network\",\n",
    "        \"IT Training\",\n",
    "        \"IT Support\",\n",
    "        'Other'\n",
    "    ] = Field(\n",
    "        description=\"Categorize the feedback into the most fitting category. If the categories provided are not a perfect fit, default to 'Other'.\"\n",
    "    )\n",
    "    #if_other: str = Field(\n",
    "        #description=\"If you chose to categorize the feedback as 'Other', return an explanation as to why and what category you think would be the best fit for the feedback.\"\n",
    "    #)\n",
    "\n",
    "\n",
    "class Categorize_bound(BaseModel):\n",
    "    # Begrenser kategoriene modellen kan velge mellom. Den får kun lov til å putte feedbacken i en av de forhåndsbestemte kategoriene.\n",
    "    \"\"\"Categorization of IT-questionaire feedback.\"\"\"\n",
    "\n",
    "    categories: Literal[\n",
    "        \"Cyber security\",\n",
    "        \"IT training\",\n",
    "        \"IT support\",\n",
    "        \"Quality of technology\",\n",
    "        \"Data quality\",\n",
    "        \"Network\",\n",
    "    ] = Field(description=\"Categorize the feedback into the most fitting category.\")\n",
    "   # rating: Optional[int] = Field(\n",
    "       # description=\"Your certainty of the corectness of the best category on a scale from 1-10\"\n",
    "  #  )\n",
    "    #reason: str = Field(\n",
    "    #    description=\"Give a short scentence as to why you think this category is the best fit.\"\n",
    "   # )\n",
    "\n",
    "\n",
    "\n",
    "class Categorize(BaseModel):\n",
    "    \"Categorization of feedback on IT-services.\"\n",
    "\n",
    "    # Thoughts: Forklar tankegangen din.\n",
    "    cat_1: str = Field(description=\"The best fitting general category. Only one.\")\n",
    "    \n",
    "class Summarize(BaseModel):\n",
    "\n",
    "    # 1. Oppsummer kategori, tar inn alle feedbacks under 1 kategori\n",
    "    # 2. Likely underlying causes of recurring issues or praises\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasettet (FLYTT TIL INTRO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "class FeedbackData:\n",
    "    \"\"\"\n",
    "    Class containing fake datasets by us :)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load a DataFrame with a specific version of a CSV\n",
    "    file_path = \"../files/raw_data_LLM101.csv\"\n",
    "    df_o = pd.read_csv(file_path)\n",
    "\n",
    "    enr_path = \"../files/random_out.csv\"\n",
    "    df = pd.read_csv(enr_path)#.head(20)\n",
    "    df_mini = df.head(5)\n",
    "\n",
    "\n",
    "# print(FeedbackData.df[\"Feedback\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kategorisering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag en funksjon som tar inn enten full prompt eller data fra undersøkelsen + pydantic objekt (struct) + modell og returnerer output fra modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KURS\n",
    "def categorize_feedback(feedback_txt : str, struktur, llm_model) -> dict:\n",
    "    # Prompt\n",
    "    task = f\"\"\"\n",
    "    Catgorize the feedback: {feedback_txt}.\n",
    "    \"\"\"\n",
    "\n",
    "    # Defining structured output for the model\n",
    "    structured_llm = llm_model.with_structured_output(   #Gå igjennom denne, hvordan bruker man structured output?\n",
    "        struktur, method=\"function_calling\"\n",
    "    )\n",
    "\n",
    "    # Prompt model\n",
    "    response = structured_llm.invoke(task)\n",
    "    # Return the response\n",
    "    return response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_feedback(feedback_txt : str, struktur, llm_model) -> dict:\n",
    "    # Prompt\n",
    "    task = f\"\"\"\n",
    "    The following feedback is from an internal survey at 'IT and Things Company' where they asked their employees for feedback on their IT-services in general.\n",
    "    Catgorize the feedback: {feedback_txt}.\n",
    "    \"\"\"\n",
    "\n",
    "    # Defining structured output for the model\n",
    "    structured_llm = llm_model.with_structured_output(\n",
    "        struktur, method=\"function_calling\"\n",
    "    )\n",
    "\n",
    "    # Prompt model\n",
    "    response = structured_llm.invoke(task)\n",
    "    # Return the response\n",
    "    return response.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Din tur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returner en dataframe med kategoriserte feedback \n",
    "# 1. Be den kategorisere uten begrensninger\n",
    "# 2. Gi den et sett med forhåndsdefinerte kategorier\n",
    "# 3. La 'other' være et alternativ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Feedback  Category_4O  \\\n",
      "0   The recent training module on cybersecurity pr...  IT Training   \n",
      "1   I appreciate the updated training materials fo...  IT Training   \n",
      "2   The scheduled training sessions have been cons...  IT Training   \n",
      "3   In the recent workshop for our CRM system, the...  IT Training   \n",
      "4   Training on modern data analytics has become m...  IT Training   \n",
      "5   Our hands-on training for remote work tools ha...  IT Training   \n",
      "6   The new onboarding process for IT training rem...  IT Training   \n",
      "7   I found the team training on system backups bo...  IT Training   \n",
      "8   The recurring training updates about IT securi...  IT Training   \n",
      "9   Our digital transformation training is well-st...  IT Training   \n",
      "10  Our network performance has been erratic, with...      Network   \n",
      "11  The daily hiccups in our VPN and internal conn...      Network   \n",
      "12  Network instability during peak hours leaves m...      Network   \n",
      "13  Although the network infrastructure is robust,...      Network   \n",
      "14  Frequent router misconfigurations lead to spor...      Network   \n",
      "15  The lag during remote access and cloudy connec...      Network   \n",
      "16  Unexpected network outages during video confer...      Network   \n",
      "17  IT-support is prompt when addressing common is...   IT Support   \n",
      "18  I greatly appreciate the help desk's willingne...   IT Support   \n",
      "19  The resolution process by IT-support is mostly...   IT Support   \n",
      "20  Every encounter with IT support brings a blend...   IT Support   \n",
      "21  IT-support's proactive assistance usually brin...   IT Support   \n",
      "22  Frequent interactions with IT-support reveal a...   IT Support   \n",
      "23  Although IT-support quickly addresses routine ...   IT Support   \n",
      "24  My experiences with IT-support are generally p...   IT Support   \n",
      "25  The new software update brought unpredictable ...   IT Support   \n",
      "26  Management decisions often appear abstract, le...        Other   \n",
      "27  While the office layout has seen improvements,...        Other   \n",
      "28  Recent changes in logistical support seem misg...        Other   \n",
      "29  New policy revisions sometimes read like riddles.   IT Support   \n",
      "30    I find myself at a loss with the latest update.   IT Support   \n",
      "31  Potato internet and unicorn protocols have bec...      Network   \n",
      "32  Internal communication appears sporadic and el...        Other   \n",
      "33  Despite the apparent order, there exists an un...        Other   \n",
      "34  I do not know how to describe the recent syste...  IT Training   \n",
      "35     The latest patch for our software didn't work.   IT Support   \n",
      "36  Intermittent issues with old hardware sometime...   IT Support   \n",
      "37  Recent leadership changes have left me with mi...        Other   \n",
      "38  The new seating arrangement in our workspace p...        Other   \n",
      "39  Office supplies seem to vanish without trace, ...        Other   \n",
      "40  Policy updates occasionally resemble riddles m...   IT Support   \n",
      "41  The recent internal memo left me scratching my...        Other   \n",
      "42  Quantum coffee breaks and mysterious break-roo...        Other   \n",
      "43  While emails fly in rapidly, the underlying me...   IT Support   \n",
      "44  There’s an inexplicable charm in the randomnes...        Other   \n",
      "45  The answers I was promised remain as abstract ...   IT Support   \n",
      "46  While the system promises efficiency with ever...   IT Support   \n",
      "47  The office printer has turned into a mysteriou...        Other   \n",
      "48  I sometimes feel like management speaks in rid...        Other   \n",
      "49  A fleeting thought crossed my mind about the n...      Network   \n",
      "\n",
      "    Category_3O  \n",
      "0   IT Training  \n",
      "1   IT Training  \n",
      "2   IT Training  \n",
      "3   IT Training  \n",
      "4   IT Training  \n",
      "5   IT Training  \n",
      "6   IT Training  \n",
      "7   IT Training  \n",
      "8   IT Training  \n",
      "9   IT Training  \n",
      "10      Network  \n",
      "11      Network  \n",
      "12      Network  \n",
      "13      Network  \n",
      "14      Network  \n",
      "15      Network  \n",
      "16      Network  \n",
      "17   IT Support  \n",
      "18   IT Support  \n",
      "19   IT Support  \n",
      "20   IT Support  \n",
      "21   IT Support  \n",
      "22   IT Support  \n",
      "23   IT Support  \n",
      "24   IT Support  \n",
      "25   IT Support  \n",
      "26        Other  \n",
      "27        Other  \n",
      "28   IT Support  \n",
      "29        Other  \n",
      "30  IT Training  \n",
      "31      Network  \n",
      "32        Other  \n",
      "33        Other  \n",
      "34        Other  \n",
      "35   IT Support  \n",
      "36   IT Support  \n",
      "37        Other  \n",
      "38        Other  \n",
      "39        Other  \n",
      "40        Other  \n",
      "41        Other  \n",
      "42        Other  \n",
      "43        Other  \n",
      "44        Other  \n",
      "45        Other  \n",
      "46   IT Support  \n",
      "47   IT Support  \n",
      "48        Other  \n",
      "49      Network  \n"
     ]
    }
   ],
   "source": [
    "## returnerer kategorisert feedback\n",
    "\n",
    "responses = []\n",
    "\n",
    "for f in FeedbackData.df[\"Feedback\"]:\n",
    "    feedback_4O = categorize_feedback(feedback_txt = f, struktur = CategorizeFromOptions, llm_model = Llm.llm)\n",
    "    feedback_3O = categorize_feedback(feedback_txt = f, struktur = CategorizeFromOptions, llm_model = LlmRes.llm)\n",
    "    responses.append({'Feedback': f, 'Category_4O': feedback_4O['category'], 'Category_3O': feedback_3O['category']})\n",
    "    #print(f)\n",
    "\n",
    "    \n",
    "cat_df = pd.DataFrame(responses)\n",
    "print(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifiser de som ble identifisert som 'other' og finn kategori for de. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others_df = cat_df[(cat_df['Category'] == 'Other') | (cat_df['Category2'] == 'Other')]\n",
    "print(others_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## returnerer kategorisert feedback\n",
    "\n",
    "# Heller send inn alle others-feedback samtidig og be den finne X nye kategorier. \n",
    "responses_new_cat = []\n",
    "\n",
    "for f in others_df[\"Feedback\"]:\n",
    "    output_i = categorize_feedback(feedback_txt = f, struktur = Categorize, llm_model = Llm.llm)\n",
    "    responses_new_cat.append({'Feedback': f,'Category': output_i[\"cat_1\"]})\n",
    "\n",
    "new_cat_df = pd.DataFrame(responses_new_cat)\n",
    "print(new_cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ny kategorisering hvor vi gir den grunnkategorier + de modellen har gjenkjent under other "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning models - when we want the LLM to return logic analyzation across rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nå vil vi teste resoneringsmodellen, sammenlikne?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization per category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Få modellen til å oppsummere per kategori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have defined fitting categories for the feedback, we can use a reasoning model to create a summary of the rows per category to provide an overall overview\n",
    "def summarize(feedback_txt : str, struktur, llm_model) -> dict:\n",
    "\n",
    "    # Prompt\n",
    "    task = f\"\"\"\n",
    "You are a domain expert in internal IT operations and organizational analysis. You will be provided with a dataset containing qualitative feedback from employees in an IT company. \n",
    "Each row in the dataset represents a feedback entry and is associated with a specific category.\n",
    "\n",
    "For each category, carefully:\n",
    "1. Read and interpret the feedback entries assigned to that category.\n",
    "2. Identify core themes, recurring patterns, and contrasting opinions within that category.\n",
    "3. Evaluate the feedback logically: What are the likely underlying causes of recurring issues or praises? Are there signs of systemic problems, isolated incidents, or misaligned expectations?\n",
    "4. Summarize each category in 3 to 6 bullet points, highlighting key sentiments (positive and negative), representative concerns or compliments, and any significant outliers\n",
    "\n",
    "Present your findings in a clean, professional way with one section per category. \n",
    "\n",
    "This is the employee feedback data: {feedback_txt}\n",
    "    \"\"\"\n",
    "\n",
    "    # Defining structured output for the model\n",
    "    structured_llm = llm_model.with_structured_output(\n",
    "        struktur, method=\"function_calling\"\n",
    "    )\n",
    "\n",
    "    # Prompt model\n",
    "    response_sum = structured_llm.invoke(task)\n",
    "    # Return the response\n",
    "    return response_sum.__dict__\n",
    "\n",
    "# Print head of response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a report for the leadership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bruk oppsummeringen til å generere en en rapport til ledelsen med forlag til forbedringspotensiale i IT. Hvilke tiltak bør bedriften gjøre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(feedback_txt : str, struktur, llm_model) -> dict:\n",
    "\n",
    "    # Prompt\n",
    "    task = f\"\"\"\n",
    "You are an expert HR and technical operations analyst. I will provide you with a dataset of employee feedback collected from an IT company.\n",
    "\n",
    "Your task is to deeply analyze this feedback and generate a concise executive-level summary report in markdown format that includes:\n",
    "\n",
    "1. Key Takeaways\n",
    "Provide a short summary of the overall feedback in 3-5 bullet points. Focus only on the main issues or areas of satisfaction.\n",
    "Include both positive and negative themes, but prioritize the most important and impactful points.\n",
    "Limit each point to 1-2 sentences.\n",
    "Before finalizing each point, take a moment to reflect on why each issue might be present (e.g., systemic problems, temporary issues, resource constraints, etc.)\n",
    "\n",
    "2. Suggested Improvements\n",
    "Based on the overall feedback, propose 2-3 high-level, actionable measures that the company could take to address the most pressing issues and enhance overall performance or satisfaction.\n",
    "Each suggestion should be brief, directly tied to the feedback, and strategic in nature.\n",
    "Think about short-term vs long-term solutions and consider the feasibility of each suggestion.\n",
    "\n",
    "3. Output\n",
    "Present your findings in a structured way with clear section headings, bullet points for easy scanning, and a consise, direct and professional tone suitable for leadership review.\n",
    "\n",
    "This is the employee feedback data: {feedback_txt}\n",
    "    \"\"\"\n",
    "\n",
    "    # Defining structured output for the model\n",
    "    structured_llm = llm_model.with_structured_output(\n",
    "        struktur, method=\"function_calling\"\n",
    "    )\n",
    "\n",
    "    # Prompt model\n",
    "    response = structured_llm.invoke(task)\n",
    "    # Return the response\n",
    "    return response.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Skulle man hatt en oppgave til slutt for de som er fort ferdig hvor de sender inn hele undersøkelsen og ber modellen velge beste kategorier før vi igjen bruker de kategoriene i structured output for å kategorisere. kjør så hele på nytt og se om du synes resultatene ble bedre. \n",
    "\n",
    "2. Hvordan kunne dette vært gjort bedre? Er det "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
