{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro til språkmodeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spørsmål\n",
    "\n",
    "- Hvordan gjør vi det med nøkler? Per nå leser denne fortsatt fra .env-filen da jeg ikke ville pushe de til github.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AzureChatOpenAI\n",
    "### Språkmodellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "# Get environment variables\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "\n",
    "class Llm:\n",
    "    \"\"\"\n",
    "    Class containing the language model.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_GPT_4O_MINI\"],\n",
    "        model=os.environ.get(\"OPENAI_MODEL_GPT_4O_MINI\", default=\"gpt-4o-mini\"),\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY_4O\"],\n",
    "        openai_api_version=os.environ[\"OPENAI_API_VERSION_4O\"],\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT_4O\"],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "\n",
    "class LlmRes:\n",
    "    \"\"\"\n",
    "    Class containing the language model.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_GPT_3O_MINI\"],\n",
    "        model=os.environ.get(\"OPENAI_MODEL_GPT_3O_MINI\", default=\"o3-mini\"),\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY_3O\"],\n",
    "        openai_api_version=os.environ[\"OPENAI_API_VERSION_3O\"],\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT_3O\"],\n",
    "        reasoning_effort=\"high\",\n",
    "        # reasoning_effort: str,\n",
    "        # Constrains effort on reasoning for reasoning models.\n",
    "        # Reasoning models only, like OpenAI o1 and o3-mini.\n",
    "        # Currently supported values are low, medium, and high.\n",
    "        # Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM = Llm()\n",
    "\n",
    "# print(Llm.llm.invoke(\"whats up?\").content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasettet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "class FeedbackData:\n",
    "    \"\"\"\n",
    "    Class containing fake datasets by us :)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load a DataFrame with a specific version of a CSV\n",
    "    file_path = \"../files/shuffled_df_LLM101_filtered.csv\"\n",
    "    df_o = pd.read_csv(file_path)\n",
    "\n",
    "    enr_path = \"../files/output_df.csv\"\n",
    "    df = pd.read_csv(enr_path)\n",
    "\n",
    "\n",
    "# print(FeedbackData.df[\"Feedback\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured output\n",
    "### Pydantic-objekter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "\n",
    "\n",
    "class Categorize_search(BaseModel):\n",
    "    \"\"\"Categorization of IT-questionaire feedback.\"\"\"\n",
    "\n",
    "    fb: str = Field(description=\"Return just the feedback verbatim.\")\n",
    "    categories: Literal[\n",
    "        \"Technology\",\n",
    "        \"IT support\",\n",
    "        \"Network\",\n",
    "        \"Other\",\n",
    "    ] = Field(\n",
    "        description=\"Categorize the feedback into the most fitting category. If the categories provided are not a perfect fit, default to 'Other'.\"\n",
    "    )\n",
    "    if_other: str = Field(\n",
    "        description=\"If you chose to categorize the feedback as 'Other', return an explanation as to why and what category you think would be the best fit for the feedback.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Categorize_bound(BaseModel):\n",
    "    # Begrenser kategoriene modellen kan velge mellom. Den får kun lov til å putte feedbacken i en av de forhåndsbestemte kategoriene.\n",
    "    \"\"\"Categorization of IT-questionaire feedback.\"\"\"\n",
    "\n",
    "    fb: str = Field(description=\"Return just the feedback verbatim.\")\n",
    "    categories: Literal[\n",
    "        \"Cyber security\",\n",
    "        \"IT training\",\n",
    "        \"IT support\",\n",
    "        \"Quality of technology\",\n",
    "        \"Data quality\",\n",
    "        \"Network\",\n",
    "    ] = Field(description=\"Categorize the feedback into the most fitting category.\")\n",
    "    rating: Optional[int] = Field(\n",
    "        description=\"Your certainty of the corectness of the best category on a scale from 1-10\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"Give a short scentence as to why you think this category is the best fit.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Categorize_think(BaseModel):\n",
    "    \"\"\"Categorization of IT-questionaire feedback.\"\"\"\n",
    "\n",
    "    cot: str = Field(\n",
    "        description=\"Think about and explain why this category is the most fitting one and why you chose it.\"\n",
    "    )\n",
    "    categories: Literal[\n",
    "        \"Cyber secyrity\", \"IT training\", \"IT support\", \"Technology quality\"\n",
    "    ] = Field(description=\"Categorize the feedback into the most fitting category.\")\n",
    "\n",
    "\n",
    "class Categorize(BaseModel):\n",
    "    \"Categorization of feedback on IT-services.\"\n",
    "\n",
    "    # Thoughts: Forklar tankegangen din.\n",
    "    fb: str = Field(description=\"Return just the feedback verbatim.\")\n",
    "    cat_1: str = Field(description=\"The best fitting general category\")\n",
    "    rating: Optional[int] = Field(\n",
    "        description=\"Your certainty of the corectness of the best category on a scale from 1-10\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Enrich(BaseModel):\n",
    "    \"Enrichment of dataset to make it more human\"\n",
    "\n",
    "    cat_1: str = Field(\n",
    "        description=\"Return the enriched dataset in a comma separated format like the format of the input dataset\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Sentiment(BaseModel):\n",
    "    \"Provide a sentiment analysis of feedback\"\n",
    "\n",
    "    fb: str = Field(description=\"Return just the feedback verbatim.\")\n",
    "    sentiment: str = Field(\n",
    "        description=\"Return the sentiment analysis of the feedback as a label. Either positive, negative or mixed.\"\n",
    "    )\n",
    "    depth_sent: str = Field(\n",
    "        description=\"Return a more nuanced analysis of the sentiment. Is there more complexity to the sentiment than just positive or negative?\"\n",
    "    )\n",
    "\n",
    "    feeling: str = Field(\n",
    "        description=\"What feelings are most predominant in the sentiment of the feedback? Return just the feeling(s).\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kategorisering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_feedback(data, struktur, llm_model):\n",
    "    # Prompt\n",
    "    task = f\"\"\"\n",
    "    The following feedback is from an internal survey at 'IT and Things Company' where they asked their employees for feedback on their IT-services in general.\n",
    "    Catgorize the feedback: {data}.\n",
    "    \"\"\"\n",
    "\n",
    "    # Giving the task to LLM\n",
    "    structured_llm = llm_model.with_structured_output(\n",
    "        struktur, method=\"function_calling\"\n",
    "    )\n",
    "\n",
    "    response = structured_llm.invoke(task)\n",
    "\n",
    "    # Return the response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Kun forhåndsbestemte kategorier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Feedback-----\n",
      " Although the system is old and its documentation remains thorough, the outdated interface sometimes creates subtle moments of confusion and occasional frustration during peak hours.\n",
      "\n",
      "-----Category-----\n",
      " 4O: Quality of technology\n",
      " 3O: Quality of technology\n",
      "\n",
      "-----Rating of certainty-----\n",
      " 4O: 8\n",
      " 3O: 9\n",
      "\n",
      "-----Reason-----\n",
      " 4O: The feedback highlights issues with the outdated interface of the system, which directly relates to the quality of technology.\n",
      " 3O: The feedback highlights issues related to the system's outdated user interface causing confusion and frustration, which directly points to the overall quality and usability of the technology.\n",
      "\n",
      "\n",
      "\n",
      "-----Feedback-----\n",
      " The step-by-step training guides for warehouse operations are mostly clear and effective; I often feel confident and even joyful when things click, although at times the dry tone leaves me wishing for more engaging details..\n",
      "\n",
      "-----Category-----\n",
      " 4O: IT training\n",
      " 3O: IT training\n",
      "\n",
      "-----Rating of certainty-----\n",
      " 4O: 8\n",
      " 3O: 9\n",
      "\n",
      "-----Reason-----\n",
      " 4O: The feedback specifically mentions training guides and the effectiveness of training, making 'IT training' the most fitting category.\n",
      " 3O: The feedback specifically discusses the training guides, noting their clarity and effectiveness, which directly aligns with IT training, despite the note about tone.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bound categorization\n",
    "\n",
    "responses_3O = {}\n",
    "responses_4O = {}\n",
    "\n",
    "for i in range(n):\n",
    "    responses_3O[str(i)] = categorize_feedback(\n",
    "        FeedbackData.df[\"Feedback\"][i], Categorize_bound, LlmRes.llm\n",
    "    )\n",
    "    responses_4O[str(i)] = categorize_feedback(FeedbackData.df[\"Feedback\"][i], Categorize_bound, Llm.llm)\n",
    "    print(f\"\\n-----Feedback-----\\n {responses_3O[str(i)].fb}\\n\")\n",
    "    print(\n",
    "        f\"-----Category-----\\n 4O: {responses_4O[str(i)].categories}\\n 3O: {responses_3O[str(i)].categories}\\n\"\n",
    "    )\n",
    "    print(\n",
    "        f\"-----Rating of certainty-----\\n 4O: {responses_4O[str(i)].rating}\\n 3O: {responses_3O[str(i)].rating}\\n\"\n",
    "    )\n",
    "    print(\n",
    "        f\"-----Reason-----\\n 4O: {responses_4O[str(i)].reason}\\n 3O: {responses_3O[str(i)].reason}\\n\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modellen velger fritt kategorier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Feedback-----\n",
      " Although the system is old and its documentation remains thorough, the outdated interface sometimes creates subtle moments of confusion and occasional frustration during peak hours..\n",
      "\n",
      "-----Category 1-----\n",
      " 4O: User Experience\n",
      " 3O: User Experience / Usability\n",
      "\n",
      "-----Rating of certainty-----\n",
      " 4O: 8\n",
      " 3O: 9\n",
      "\n",
      "\n",
      "\n",
      "-----Feedback-----\n",
      " The step-by-step training guides for warehouse operations are mostly clear and effective; I often feel confident and even joyful when things click, although at times the dry tone leaves me wishing for more engaging details..\n",
      "\n",
      "-----Category 1-----\n",
      " 4O: Training and Documentation\n",
      " 3O: Training & Documentation\n",
      "\n",
      "-----Rating of certainty-----\n",
      " 4O: 8\n",
      " 3O: 9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "responses_3O = {}\n",
    "responses_4O = {}\n",
    "\n",
    "for i in range(n):\n",
    "    responses_3O[str(i)] = categorize_feedback(\n",
    "        FeedbackData.df[\"Feedback\"][i], Categorize ,LlmRes.llm\n",
    "    )\n",
    "    responses_4O[str(i)] = categorize_feedback(FeedbackData.df[\"Feedback\"][i], Categorize, Llm.llm)\n",
    "    print(f\"\\n-----Feedback-----\\n {responses_3O[str(i)].fb}\\n\")\n",
    "    print(\n",
    "        f\"-----Category 1-----\\n 4O: {responses_4O[str(i)].cat_1}\\n 3O: {responses_3O[str(i)].cat_1}\\n\"\n",
    "    )\n",
    "    print(\n",
    "        f\"-----Rating of certainty-----\\n 4O: {responses_4O[str(i)].rating}\\n 3O: {responses_3O[str(i)].rating}\\n\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gi noen kategorier + 'other' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Feedback-----\n",
      " Although the system is old and its documentation remains thorough, the outdated interface sometimes creates subtle moments of confusion and occasional frustration during peak hours.\n",
      "\n",
      "-----Category-----\n",
      " 4O: Technology\n",
      " 3O: Technology\n",
      "\n",
      "-----If other-----\n",
      " 4O: \n",
      " 3O: \n",
      "\n",
      "\n",
      "-----Feedback-----\n",
      " The step-by-step training guides for warehouse operations are mostly clear and effective; I often feel confident and even joyful when things click, although at times the dry tone leaves me wishing for more engaging details.\n",
      "\n",
      "-----Category-----\n",
      " 4O: Other\n",
      " 3O: IT support\n",
      "\n",
      "-----If other-----\n",
      " 4O: This feedback pertains to training materials rather than a specific IT service, making it difficult to categorize under Technology, IT support, or Network. The best fit would be 'Training and Development'.\n",
      " 3O: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "responses_3O = {}\n",
    "responses_4O = {}\n",
    "\n",
    "for i in range(n):\n",
    "    responses_3O[i] = categorize_feedback(FeedbackData.df[\"Feedback\"][i], Categorize_search, LlmRes.llm)\n",
    "    responses_4O[i] = categorize_feedback(FeedbackData.df[\"Feedback\"][i], Categorize_search, Llm.llm)\n",
    "    print(f\"\\n-----Feedback-----\\n {responses_3O[i].fb}\\n\")\n",
    "    print(\n",
    "        f\"-----Category-----\\n 4O: {responses_4O[i].categories}\\n 3O: {responses_3O[i].categories}\\n\"\n",
    "    )\n",
    "    print(\n",
    "        f\"-----If other-----\\n 4O: {responses_4O[i].if_other}\\n 3O: {responses_3O[i].if_other}\\n\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
